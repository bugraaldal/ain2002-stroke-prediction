{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling & Inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from feature_engine.selection import RecursiveFeatureElimination\n",
    "from sklearn.model_selection import train_test_split\n",
    "from feature_engine.encoding import RareLabelEncoder\n",
    "from feature_engine.encoding import StringSimilarityEncoder\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from feature_engine.encoding import CountFrequencyEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import average_precision_score\n",
    "from scipy.stats import ks_2samp\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost.callback import EarlyStopping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSVs\n",
    "real_world_df = pd.read_csv('./data/real-world-data/healthcare-dataset-stroke-data.csv', index_col=0)\n",
    "train_synthetic_df = pd.read_csv(\"./data/synthetic-data/train.csv\", index_col=0)\n",
    "test_df = pd.read_csv('./data/synthetic-data/test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>79.53</td>\n",
       "      <td>31.1</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>78.44</td>\n",
       "      <td>23.9</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>103.00</td>\n",
       "      <td>40.3</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>64.87</td>\n",
       "      <td>28.8</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>73.36</td>\n",
       "      <td>28.8</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease ever_married work_type   \n",
       "0    Male  28.0             0              0          Yes   Private  \\\n",
       "1    Male  33.0             0              0          Yes   Private   \n",
       "2  Female  42.0             0              0          Yes   Private   \n",
       "3    Male  56.0             0              0          Yes   Private   \n",
       "4  Female  24.0             0              0           No   Private   \n",
       "\n",
       "  Residence_type  avg_glucose_level   bmi   smoking_status  stroke  \n",
       "0          Urban              79.53  31.1     never smoked       0  \n",
       "1          Rural              78.44  23.9  formerly smoked       0  \n",
       "2          Rural             103.00  40.3          Unknown       0  \n",
       "3          Urban              64.87  28.8     never smoked       0  \n",
       "4          Rural              73.36  28.8     never smoked       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([train_synthetic_df, real_world_df], ignore_index=True, axis=0)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "s_categorical = [\"gender\", \"ever_married\", \"work_type\", \"Residence_type\", \"smoking_status\"]\n",
    "binary = [\"hypertension\", \"heart_disease\"] # Basically, categorical values with only 2 values. 1 or 0\n",
    "continous_numerical = [\"age\", \"avg_glucose_level\", \"bmi\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Decision Tree to predict the missing BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after decision tree regressor:  0\n"
     ]
    }
   ],
   "source": [
    "DT_bmi_pipe = Pipeline( steps=[ \n",
    "                               (\"scale\",StandardScaler()),\n",
    "                               (\"lr\",DecisionTreeRegressor(random_state=42))\n",
    "                              ])\n",
    "dt_df = df.copy()\n",
    "X = dt_df[[\"age\",\"gender\",\"bmi\"]].copy()\n",
    "X.gender = X.gender.replace({\"Male\":0,\"Female\":1,\"Other\":-1}).astype(np.uint8)\n",
    "\n",
    "missing = X[X.bmi.isna()]\n",
    "X = X[~X.bmi.isna()]\n",
    "Y = X.pop(\"bmi\")\n",
    "DT_bmi_pipe.fit(X,Y)\n",
    "predicted_bmi = pd.Series(DT_bmi_pipe.predict(missing[[\"age\",\"gender\"]]),index=missing.index)\n",
    "dt_df.loc[missing.index,\"bmi\"] = predicted_bmi\n",
    "\n",
    "print(\"Missing values after decision tree regressor: \",sum(dt_df.isnull().sum()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Simple Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after imputing:  0\n"
     ]
    }
   ],
   "source": [
    "mean_imputer = SimpleImputer(strategy=\"mean\")\n",
    "imputed_df = df.copy()\n",
    "imputed_df[\"bmi\"] = mean_imputer.fit_transform(imputed_df[\"bmi\"].values.reshape(-1,1))\n",
    "print(\"Missing values after imputing: \",sum(imputed_df.isnull().sum()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def baseline(train_df, cv, oof_preds, target, train_auc, val_auc, pipelines, model, encoder, scaler):\n",
    "    # cast categorical features as categorical type\n",
    "    train_df[s_categorical] = (train_df[s_categorical].astype(\"category\"))\n",
    "    for fold, (train_indx, val_indx) in enumerate(cv.split(train_df, target)):\n",
    "        X_train, Y_train = train_df.iloc[train_indx], target.iloc[train_indx]\n",
    "        X_val, Y_val = train_df.iloc[val_indx], target.iloc[val_indx]\n",
    "        \n",
    "        X_train = X_train.copy()\n",
    "        X_val = X_val.copy()\n",
    "        \n",
    "\n",
    "\n",
    "        X_train = encoder.fit_transform(X_train)\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        \n",
    "        X_val = encoder.transform(X_val)\n",
    "        X_val = scaler.transform(X_val)\n",
    "\n",
    "        print(\"_\"*50)\n",
    "        \n",
    "        model.fit(X_train, Y_train)\n",
    "        \n",
    "        oof_preds.iloc[val_indx] = model.predict_proba(X_val)[:, 1]\n",
    "        train_auc.append(roc_auc_score(Y_train, model.predict_proba(X_train)[:, 1]))\n",
    "        val_auc.append(roc_auc_score(Y_val, model.predict_proba(X_val)[:, 1]))\n",
    "        pipelines.append([encoder, scaler, model])\n",
    "\n",
    "        print(f\"Val AUC: {val_auc[-1]}\")\n",
    "    return pipelines, train_auc, val_auc, oof_preds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline with Logistic Regression + OneHot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(shuffle=True, random_state=42)\n",
    "features = s_categorical + continous_numerical\n",
    "model = LogisticRegression()\n",
    "encoder = OneHotEncoder(drop_last=True, variables=s_categorical)\n",
    "scaler = SklearnTransformerWrapper(StandardScaler(), variables=continous_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "Val AUC: 0.882504529352911\n",
      "__________________________________________________\n",
      "Val AUC: 0.8824828966225899\n",
      "__________________________________________________\n",
      "Val AUC: 0.8923830840163384\n",
      "__________________________________________________\n",
      "Val AUC: 0.8760177983886983\n",
      "__________________________________________________\n",
      "Val AUC: 0.8797080750045986\n",
      "\n",
      "Synthetic Train AUC: 0.8849088476136592\n",
      "Synthetic Val AUC: 0.8826192766770273\n",
      "Synthetic OOF AUC score: 0.8824682638419171\n"
     ]
    }
   ],
   "source": [
    "train_auc = []\n",
    "val_auc = []\n",
    "pipelines = []\n",
    "oof_preds = pd.Series(0, index=train_synthetic_df.index)\n",
    "\n",
    "train_df = train_synthetic_df[features].copy()\n",
    "target = train_synthetic_df[\"stroke\"]\n",
    "\n",
    "_, train_auc, val_auc, oof_preds_synth = baseline(train_df, cv, oof_preds, target, train_auc, val_auc, pipelines, model, encoder, scaler)\n",
    "print()\n",
    "print(f\"Synthetic Train AUC: {np.mean(train_auc)}\")\n",
    "print(f\"Synthetic Val AUC: {np.mean(val_auc)}\")\n",
    "print(f\"Synthetic OOF AUC score: {roc_auc_score(target, oof_preds_synth)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "Val AUC: 0.8719053214510086\n",
      "__________________________________________________\n",
      "Val AUC: 0.8716042883402749\n",
      "__________________________________________________\n",
      "Val AUC: 0.8677119447611514\n",
      "__________________________________________________\n",
      "Val AUC: 0.881850607930433\n",
      "__________________________________________________\n",
      "Val AUC: 0.8670329446539125\n",
      "\n",
      "Imputed with mean Train AUC: 0.8736126228638372\n",
      "Imputed with mean Val AUC: 0.872021021427356\n",
      "Imputed with mean OOF AUC score: 0.8719507131706968\n"
     ]
    }
   ],
   "source": [
    "train_auc = []\n",
    "val_auc = []\n",
    "pipelines = []\n",
    "oof_preds = pd.Series(0, index=imputed_df.index)\n",
    "\n",
    "imputed_df_train = imputed_df[features].copy()\n",
    "target = imputed_df[\"stroke\"]\n",
    "\n",
    "_, train_auc, val_auc, oof_preds_imputed = baseline(imputed_df_train, cv, oof_preds, target, train_auc, val_auc, pipelines, model, encoder, scaler)\n",
    "print()\n",
    "print(f\"Imputed with mean Train AUC: {np.mean(train_auc)}\")\n",
    "print(f\"Imputed with mean Val AUC: {np.mean(val_auc)}\")\n",
    "print(f\"Imputed with mean OOF AUC score: {roc_auc_score(target, oof_preds_imputed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "Val AUC: 0.8718835074574773\n",
      "__________________________________________________\n",
      "Val AUC: 0.8715606603532123\n",
      "__________________________________________________\n",
      "Val AUC: 0.8678384659236336\n",
      "__________________________________________________\n",
      "Val AUC: 0.8819489645077399\n",
      "__________________________________________________\n",
      "Val AUC: 0.8672060466415304\n",
      "\n",
      "Desicion Tree Train AUC: 0.8736964244001928\n",
      "Desicion Tree Val AUC: 0.8720875289767186\n",
      "Desicion Tree OOF AUC score: 0.8720377046952121\n"
     ]
    }
   ],
   "source": [
    "train_auc = []\n",
    "val_auc = []\n",
    "pipelines = []\n",
    "oof_preds = pd.Series(0, index=dt_df.index)\n",
    "\n",
    "dt_df_train = dt_df[features].copy()\n",
    "target = dt_df[\"stroke\"]\n",
    "\n",
    "_, train_auc, val_auc, oof_preds_dt = baseline(dt_df_train, cv, oof_preds, target, train_auc, val_auc, pipelines, model, encoder, scaler)\n",
    "print()\n",
    "print(f\"Desicion Tree Train AUC: {np.mean(train_auc)}\")\n",
    "print(f\"Desicion Tree Val AUC: {np.mean(val_auc)}\")\n",
    "print(f\"Desicion Tree OOF AUC score: {roc_auc_score(target, oof_preds_dt)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that synthetic data fits the best to our pipeline. Let's try other encoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "Val AUC: 0.8828614694032071\n",
      "__________________________________________________\n",
      "Val AUC: 0.8822422324977691\n",
      "__________________________________________________\n",
      "Val AUC: 0.8924340745750339\n",
      "__________________________________________________\n",
      "Val AUC: 0.8686778416501618\n",
      "__________________________________________________\n",
      "Val AUC: 0.875850726566473\n",
      "\n",
      "Synthetic CountFrequencyEncoder Train AUC: 0.8817984049890443\n",
      "Synthetic CountFrequencyEncoder Val AUC: 0.8804132689385291\n",
      "Synthetic CountFrequencyEncoder OOF AUC: 0.8802621112460831\n"
     ]
    }
   ],
   "source": [
    "encoder = CountFrequencyEncoder(variables=s_categorical)\n",
    "train_auc = []\n",
    "val_auc = []\n",
    "pipelines = []\n",
    "oof_preds = pd.Series(0, index=train_synthetic_df.index)\n",
    "target = train_synthetic_df[\"stroke\"]\n",
    "pipelines, train_auc, val_auc, oof_preds_f = baseline(train_df, cv, oof_preds, target, train_auc, val_auc, pipelines, model, encoder, scaler)\n",
    "print()\n",
    "print(f\"Synthetic CountFrequencyEncoder Train AUC: {np.mean(train_auc)}\")\n",
    "print(f\"Synthetic CountFrequencyEncoder Val AUC: {np.mean(val_auc)}\")\n",
    "print(f\"Synthetic CountFrequencyEncoder OOF AUC: {roc_auc_score(target, oof_preds_f)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "Val AUC: 0.8825829480003246\n",
      "__________________________________________________\n",
      "Val AUC: 0.8824801925312998\n",
      "__________________________________________________\n",
      "Val AUC: 0.8924743302792673\n",
      "__________________________________________________\n",
      "Val AUC: 0.8759990123933894\n",
      "__________________________________________________\n",
      "Val AUC: 0.8797432401726881\n",
      "\n",
      "Synthetic StringSimilarityEncoder Train AUC: 0.8849180160213044\n",
      "StringSimilarityEncoder Val AUC: 0.8826559446753939\n",
      "StringSimilarityEncoder OOF AUC score: 0.8825379306834338\n"
     ]
    }
   ],
   "source": [
    "encoder = StringSimilarityEncoder(variables=s_categorical)\n",
    "train_auc = []\n",
    "val_auc = []\n",
    "pipelines = []\n",
    "oof_preds = pd.Series(0, index=train_synthetic_df.index)\n",
    "target = train_synthetic_df[\"stroke\"]\n",
    "pipelines, train_auc, val_auc, oof_preds_ss = baseline(train_df, cv, oof_preds, target, train_auc, val_auc, pipelines, model, encoder, scaler)\n",
    "print()\n",
    "print(f\"Synthetic StringSimilarityEncoder Train AUC: {np.mean(train_auc)}\")\n",
    "print(f\"StringSimilarityEncoder Val AUC: {np.mean(val_auc)}\")\n",
    "print(f\"StringSimilarityEncoder OOF AUC score: {roc_auc_score(target, oof_preds_ss)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that StringSimilarityEncoder gives the highest score but its method doesn't make much sense to us. Our best choice for encoders is OneHotEncoder.   \n",
    "We will try a submission with StringSimilarityEncoder as well."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The Kolmogorov–Smirnov test is a nonparametric goodness-of-fit test and is used to determine wether two distributions differ, or whether an underlying probability distribution differes from a hypothesized distribution. It is used when we have two samples coming from two populations that can be different.  \n",
    "\n",
    ">If the p-value is lower than our threshold of 0.05, so we reject the null hypothesis in favor of the default “two-sided” alternative: the data were not drawn from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.6091470190356556, pvalue=2.4700771372158504e-216, statistic_location=0.0410081412417565, statistic_sign=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_2samp(oof_preds_synth[target==0], oof_preds_synth[target==1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying RecursiveFeatureElimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0900333374972037\n",
      "{'avg_glucose_level': 0.0114814154900168, 'bmi': 0.002188074390195749, 'age': 0.04421995300609483, 'heart_disease': 0.000671441535687517, 'hypertension': 0.006686764700367692}\n",
      "['hypertension', 'heart_disease', 'bmi']\n"
     ]
    }
   ],
   "source": [
    "# initialize linear regresion estimator\n",
    "X = train_synthetic_df.drop(\"stroke\", axis=1)\n",
    "y = train_synthetic_df[\"stroke\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# initialize feature selector\n",
    "tr = RecursiveFeatureElimination(estimator=linear_model, scoring=\"r2\", cv=3)\n",
    "Xt = tr.fit_transform(X_train, y_train)\n",
    "print(tr.initial_model_performance_)\n",
    "print(tr.performance_drifts_)\n",
    "print(tr.features_to_drop_)\n",
    "del X, y, X_train, X_test, y_train, y_test, linear_model, tr, Xt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df):\n",
    "    df['age/bmi'] = df.age / df.bmi\n",
    "    df['age*bmi'] = df.age * df.bmi\n",
    "    df['bmi/prime'] = df.bmi / 25\n",
    "    df['obesity'] = df.avg_glucose_level * df.bmi / 1000\n",
    "    df['blood_heart']= df.hypertension*df.heart_disease\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = s_categorical + binary\n",
    "features = categorical + continous_numerical + ['age/bmi', 'age*bmi', 'bmi/prime', 'obesity', 'blood_heart']\n",
    "rfe_features =[\n",
    "    'age', 'avg_glucose_level', 'bmi', 'ever_married_Yes', 'gender_Male',\n",
    "    'hypertension_0', 'smoking_status_Unknown', 'smoking_status_formerly smoked',\n",
    "    'smoking_status_never smoked', 'work_type_Self-employed', 'work_type_children'\n",
    "]\n",
    "\n",
    "fill_unknown = 'never smoked'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_world_df = pd.read_csv(\n",
    "    './data/real-world-data/healthcare-dataset-stroke-data.csv',\n",
    "    index_col=0\n",
    ")\n",
    "\n",
    "train_df = pd.read_csv('./data/synthetic-data/train.csv', index_col=0)\n",
    "test_df = pd.read_csv('./data/synthetic-data/test.csv', index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoost_model(synthetic_train_df, real_world_df, train_df, test_df_c, real_world_target, encoder):\n",
    "    # cast categorical features as categorical type\n",
    "    synthetic_train_df[categorical] = (synthetic_train_df[categorical].astype('category'))\n",
    "    real_world_df[categorical] = (real_world_df[categorical].astype('category'))\n",
    "\n",
    "\n",
    "    target = train_df['stroke']\n",
    "    # Grab Target\n",
    "    oof_preds = pd.Series(0, index=train_df.index, name='stroke')\n",
    "    test_preds = pd.Series(0, index=test_df.index, name='stroke')\n",
    "\n",
    "    train_auc, val_auc = [], []\n",
    "    pipelines = []\n",
    "\n",
    "    for fold, (train_indx, val_indx) in enumerate(cv.split(train_df, target)):\n",
    "        pipeline = []\n",
    "        X_train, y_train = synthetic_train_df.iloc[train_indx], target.iloc[train_indx]\n",
    "        X_val, y_val = synthetic_train_df.iloc[val_indx], target.iloc[val_indx]\n",
    "        X_test = test_df_c.copy()\n",
    "\n",
    "        # concat prev dataset\n",
    "        X_train = pd.concat([X_train, real_world_df], axis=0)\n",
    "        y_train = pd.concat([y_train, real_world_target])\n",
    "\n",
    "        X_train = X_train.copy()\n",
    "        X_val = X_val.copy()\n",
    "\n",
    "\n",
    "        model = XGBClassifier(\n",
    "            random_state=42, learning_rate=1e-2,\n",
    "            n_estimators=3000,\n",
    "            tree_method='gpu_hist',\n",
    "            callbacks=[\n",
    "                EarlyStopping(100, save_best=True, maximize=False),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Fit encoder\n",
    "        X_train = encoder.fit_transform(X_train)\n",
    "        X_val = encoder.transform(X_val)\n",
    "        X_test = encoder.transform(X_test)\n",
    "        pipeline.append(encoder)\n",
    "\n",
    "        # filter columns by RFE columns\n",
    "        X_train = X_train[X_train.columns.intersection(rfe_features)]\n",
    "        X_val = X_val[X_val.columns.intersection(rfe_features)]\n",
    "        X_test = X_test[X_test.columns.intersection(rfe_features)]\n",
    "\n",
    "        print('_'*50)\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val,y_val)],\n",
    "            verbose=1000,\n",
    "        )\n",
    "\n",
    "        oof_preds.iloc[val_indx] = model.predict_proba(X_val)[:, 1]\n",
    "        test_preds += model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        train_auc.append(roc_auc_score(y_train, model.predict_proba(X_train)[:, 1]))\n",
    "        val_auc.append(roc_auc_score(y_val, model.predict_proba(X_val)[:, 1]))\n",
    "\n",
    "        pipeline.append(model)\n",
    "        pipelines.append(pipeline)\n",
    "\n",
    "        print(f'Val AUC: {val_auc[-1]}')\n",
    "\n",
    "    print()\n",
    "    print(f'Mean Val AUC: {np.mean(val_auc)}')\n",
    "    print(f'OOF AUC: {roc_auc_score(target, oof_preds)}')\n",
    "    return test_preds, pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Generate feature engineering\n",
    "synthetic_train_df = generate_features(train_df.copy())\n",
    "test_df_c = generate_features(test_df.copy())\n",
    "real_world_df = generate_features(real_world_df.copy())\n",
    "\n",
    "real_world_target = real_world_df[\"stroke\"]\n",
    "\n",
    "# filter features \n",
    "synthetic_train_df = synthetic_train_df[features]\n",
    "test_df_c = test_df_c[features]\n",
    "real_world_df = real_world_df[features]\n",
    "\n",
    "#IMPUTE VS VS\n",
    "# fill nan values on original dataset\n",
    "fills = real_world_df.mean(axis=0, numeric_only=True)\n",
    "real_world_df.fillna(fills, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68453\n",
      "[930]\tvalidation_0-logloss:0.12712\n",
      "Val AUC: 0.8864452229574844\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68455\n",
      "[644]\tvalidation_0-logloss:0.12763\n",
      "Val AUC: 0.8772976947363869\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68448\n",
      "[583]\tvalidation_0-logloss:0.12509\n",
      "Val AUC: 0.8803521216768916\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68457\n",
      "[776]\tvalidation_0-logloss:0.12507\n",
      "Val AUC: 0.8954925017041582\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68453\n",
      "[757]\tvalidation_0-logloss:0.12277\n",
      "Val AUC: 0.8922322848703216\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68454\n",
      "[651]\tvalidation_0-logloss:0.12744\n",
      "Val AUC: 0.8863569967864446\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68453\n",
      "[704]\tvalidation_0-logloss:0.12507\n",
      "Val AUC: 0.8835546033910042\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68451\n",
      "[775]\tvalidation_0-logloss:0.13057\n",
      "Val AUC: 0.8740654180326981\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68457\n",
      "[695]\tvalidation_0-logloss:0.12831\n",
      "Val AUC: 0.8828350699516343\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68456\n",
      "[773]\tvalidation_0-logloss:0.12521\n",
      "Val AUC: 0.8843336471148332\n",
      "\n",
      "Mean Val AUC: 0.8842965561221856\n",
      "OOF AUC: 0.8840207775423436\n"
     ]
    }
   ],
   "source": [
    "preds_ss, pipelines = XGBoost_model(synthetic_train_df, real_world_df, train_df, test_df_c, real_world_target, encoder=StringSimilarityEncoder(variables=categorical))\n",
    "preds_ss /= len(pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68455\n",
      "[804]\tvalidation_0-logloss:0.12690\n",
      "Val AUC: 0.8832230439859867\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68454\n",
      "[877]\tvalidation_0-logloss:0.12842\n",
      "Val AUC: 0.8747783400371956\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68449\n",
      "[575]\tvalidation_0-logloss:0.12492\n",
      "Val AUC: 0.8806396983640081\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68457\n",
      "[710]\tvalidation_0-logloss:0.12429\n",
      "Val AUC: 0.8992309986366734\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68454\n",
      "[756]\tvalidation_0-logloss:0.12264\n",
      "Val AUC: 0.8949589379037233\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68455\n",
      "[644]\tvalidation_0-logloss:0.12700\n",
      "Val AUC: 0.8885967474924531\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68453\n",
      "[706]\tvalidation_0-logloss:0.12474\n",
      "Val AUC: 0.8843877473734325\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68451\n",
      "[1000]\tvalidation_0-logloss:0.12913\n",
      "[1314]\tvalidation_0-logloss:0.12849\n",
      "Val AUC: 0.8809902511334005\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68455\n",
      "[762]\tvalidation_0-logloss:0.12622\n",
      "Val AUC: 0.8874444119842894\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68456\n",
      "[734]\tvalidation_0-logloss:0.12584\n",
      "Val AUC: 0.8852317114075805\n",
      "\n",
      "Mean Val AUC: 0.8859481888318743\n",
      "OOF AUC: 0.8856868503513107\n"
     ]
    }
   ],
   "source": [
    "preds_oh, pipelines = XGBoost_model(synthetic_train_df, real_world_df, train_df, test_df_c, real_world_target, encoder=OneHotEncoder(variables=categorical))\n",
    "preds_oh /= len(pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "15304    0.051600\n",
       "15305    0.172296\n",
       "15306    0.001811\n",
       "15307    0.051274\n",
       "15308    0.011238\n",
       "           ...   \n",
       "25503    0.001839\n",
       "25504    0.009145\n",
       "25505    0.001947\n",
       "25506    0.003292\n",
       "25507    0.001868\n",
       "Name: stroke, Length: 10204, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "15304    0.049530\n",
       "15305    0.159378\n",
       "15306    0.001665\n",
       "15307    0.042521\n",
       "15308    0.007461\n",
       "           ...   \n",
       "25503    0.001647\n",
       "25504    0.009171\n",
       "25505    0.001783\n",
       "25506    0.003157\n",
       "25507    0.001709\n",
       "Name: stroke, Length: 10204, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_oh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in our LogisticRegressor, StringSimilarityEncoder fits *very slightly* better than OneHotEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ss.rename('stroke', inplace=True)\n",
    "preds_ss.to_csv('submission_ss.csv') # Public Score: 0.8672\n",
    "preds_oh.rename('stroke', inplace=True)\n",
    "preds_oh.to_csv('submission_oh.csv')  # Public Score: 0.8670"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
