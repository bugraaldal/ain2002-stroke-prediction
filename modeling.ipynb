{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling & Inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from feature_engine.selection import RecursiveFeatureElimination\n",
    "from sklearn.model_selection import train_test_split\n",
    "from feature_engine.encoding import StringSimilarityEncoder\n",
    "from feature_engine.encoding import CountFrequencyEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from scipy.stats import ks_2samp\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost.callback import EarlyStopping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSVs\n",
    "real_world_df = pd.read_csv('./data/real-world-data/healthcare-dataset-stroke-data.csv', index_col=0)\n",
    "train_synthetic_df = pd.read_csv(\"./data/synthetic-data/train.csv\", index_col=0)\n",
    "test_df = pd.read_csv('./data/synthetic-data/test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>79.53</td>\n",
       "      <td>31.1</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>78.44</td>\n",
       "      <td>23.9</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>103.00</td>\n",
       "      <td>40.3</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>64.87</td>\n",
       "      <td>28.8</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>73.36</td>\n",
       "      <td>28.8</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease ever_married work_type   \n",
       "0    Male  28.0             0              0          Yes   Private  \\\n",
       "1    Male  33.0             0              0          Yes   Private   \n",
       "2  Female  42.0             0              0          Yes   Private   \n",
       "3    Male  56.0             0              0          Yes   Private   \n",
       "4  Female  24.0             0              0           No   Private   \n",
       "\n",
       "  Residence_type  avg_glucose_level   bmi   smoking_status  stroke  \n",
       "0          Urban              79.53  31.1     never smoked       0  \n",
       "1          Rural              78.44  23.9  formerly smoked       0  \n",
       "2          Rural             103.00  40.3          Unknown       0  \n",
       "3          Urban              64.87  28.8     never smoked       0  \n",
       "4          Rural              73.36  28.8     never smoked       0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([train_synthetic_df, real_world_df], ignore_index=True, axis=0)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "s_categorical = [\"gender\", \"ever_married\", \"work_type\", \"Residence_type\", \"smoking_status\"]\n",
    "binary = [\"hypertension\", \"heart_disease\"] # Basically, categorical values with only 2 values. 1 or 0\n",
    "continous_numerical = [\"age\", \"avg_glucose_level\", \"bmi\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def baseline(train_df, cv, oof_preds, target, train_auc, val_auc, pipelines, model, encoder, scaler):\n",
    "    # cast categorical features as categorical type\n",
    "    train_df[s_categorical] = (train_df[s_categorical].astype(\"category\"))\n",
    "    for fold, (train_indx, val_indx) in enumerate(cv.split(train_df, target)):\n",
    "        X_train, Y_train = train_df.iloc[train_indx], target.iloc[train_indx]\n",
    "        X_val, Y_val = train_df.iloc[val_indx], target.iloc[val_indx]\n",
    "        \n",
    "        X_train = X_train.copy()\n",
    "        X_val = X_val.copy()\n",
    "        \n",
    "\n",
    "\n",
    "        X_train = encoder.fit_transform(X_train)\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        \n",
    "        X_val = encoder.transform(X_val)\n",
    "        X_val = scaler.transform(X_val)\n",
    "\n",
    "        print(\"_\"*50)\n",
    "        \n",
    "        model.fit(X_train, Y_train)\n",
    "        \n",
    "        oof_preds.iloc[val_indx] = model.predict_proba(X_val)[:, 1]\n",
    "        train_auc.append(roc_auc_score(Y_train, model.predict_proba(X_train)[:, 1]))\n",
    "        val_auc.append(roc_auc_score(Y_val, model.predict_proba(X_val)[:, 1]))\n",
    "        pipelines.append([encoder, scaler, model])\n",
    "\n",
    "        print(f\"Val AUC: {val_auc[-1]}\")\n",
    "    return pipelines, train_auc, val_auc, oof_preds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline with Logistic Regression + OneHot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(shuffle=True, random_state=42)\n",
    "features = s_categorical + continous_numerical\n",
    "model = LogisticRegression()\n",
    "encoder = OneHotEncoder(drop_last=True, variables=s_categorical)\n",
    "scaler = SklearnTransformerWrapper(StandardScaler(), variables=continous_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "Val AUC: 0.882504529352911\n",
      "__________________________________________________\n",
      "Val AUC: 0.8824828966225899\n",
      "__________________________________________________\n",
      "Val AUC: 0.8923830840163384\n",
      "__________________________________________________\n",
      "Val AUC: 0.8760177983886983\n",
      "__________________________________________________\n",
      "Val AUC: 0.8797080750045986\n",
      "\n",
      "Synthetic Train AUC: 0.8849088476136592\n",
      "Synthetic Val AUC: 0.8826192766770273\n",
      "Synthetic OOF AUC score: 0.8824682638419171\n"
     ]
    }
   ],
   "source": [
    "train_auc = []\n",
    "val_auc = []\n",
    "pipelines = []\n",
    "oof_preds = pd.Series(0, index=train_synthetic_df.index)\n",
    "\n",
    "train_df = train_synthetic_df[features].copy()\n",
    "target = train_synthetic_df[\"stroke\"]\n",
    "\n",
    "_, train_auc, val_auc, oof_preds_synth = baseline(train_df, cv, oof_preds, target, train_auc, val_auc, pipelines, model, encoder, scaler)\n",
    "print()\n",
    "print(f\"Synthetic Train AUC: {np.mean(train_auc)}\")\n",
    "print(f\"Synthetic Val AUC: {np.mean(val_auc)}\")\n",
    "print(f\"Synthetic OOF AUC score: {roc_auc_score(target, oof_preds_synth)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try other encoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "Val AUC: 0.8828614694032071\n",
      "__________________________________________________\n",
      "Val AUC: 0.8822422324977691\n",
      "__________________________________________________\n",
      "Val AUC: 0.8924340745750339\n",
      "__________________________________________________\n",
      "Val AUC: 0.8686778416501618\n",
      "__________________________________________________\n",
      "Val AUC: 0.875850726566473\n",
      "\n",
      "Synthetic CountFrequencyEncoder Train AUC: 0.8817984049890443\n",
      "Synthetic CountFrequencyEncoder Val AUC: 0.8804132689385291\n",
      "Synthetic CountFrequencyEncoder OOF AUC: 0.8802621112460831\n"
     ]
    }
   ],
   "source": [
    "encoder = CountFrequencyEncoder(variables=s_categorical)\n",
    "train_auc = []\n",
    "val_auc = []\n",
    "pipelines = []\n",
    "oof_preds = pd.Series(0, index=train_synthetic_df.index)\n",
    "target = train_synthetic_df[\"stroke\"]\n",
    "pipelines, train_auc, val_auc, oof_preds_f = baseline(train_df, cv, oof_preds, target, train_auc, val_auc, pipelines, model, encoder, scaler)\n",
    "print()\n",
    "print(f\"Synthetic CountFrequencyEncoder Train AUC: {np.mean(train_auc)}\")\n",
    "print(f\"Synthetic CountFrequencyEncoder Val AUC: {np.mean(val_auc)}\")\n",
    "print(f\"Synthetic CountFrequencyEncoder OOF AUC: {roc_auc_score(target, oof_preds_f)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "Val AUC: 0.8825829480003246\n",
      "__________________________________________________\n",
      "Val AUC: 0.8824801925312998\n",
      "__________________________________________________\n",
      "Val AUC: 0.8924743302792673\n",
      "__________________________________________________\n",
      "Val AUC: 0.8759990123933894\n",
      "__________________________________________________\n",
      "Val AUC: 0.8797432401726881\n",
      "\n",
      "Synthetic StringSimilarityEncoder Train AUC: 0.8849180160213044\n",
      "StringSimilarityEncoder Val AUC: 0.8826559446753939\n",
      "StringSimilarityEncoder OOF AUC score: 0.8825379306834338\n"
     ]
    }
   ],
   "source": [
    "encoder = StringSimilarityEncoder(variables=s_categorical)\n",
    "train_auc = []\n",
    "val_auc = []\n",
    "pipelines = []\n",
    "oof_preds = pd.Series(0, index=train_synthetic_df.index)\n",
    "target = train_synthetic_df[\"stroke\"]\n",
    "pipelines, train_auc, val_auc, oof_preds_ss = baseline(train_df, cv, oof_preds, target, train_auc, val_auc, pipelines, model, encoder, scaler)\n",
    "print()\n",
    "print(f\"Synthetic StringSimilarityEncoder Train AUC: {np.mean(train_auc)}\")\n",
    "print(f\"StringSimilarityEncoder Val AUC: {np.mean(val_auc)}\")\n",
    "print(f\"StringSimilarityEncoder OOF AUC score: {roc_auc_score(target, oof_preds_ss)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that StringSimilarityEncoder gives the highest score but its method doesn't make much sense to us. Our best choice for encoders is OneHotEncoder.   \n",
    "We will try a submission with StringSimilarityEncoder as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds_ss.rename('stroke', inplace=True)\n",
    "oof_preds_ss.to_csv('./submissions/submission_oof.csv')  # Public Score: 0.86705"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The Kolmogorov–Smirnov test is a nonparametric goodness-of-fit test and is used to determine wether two distributions differ, or whether an underlying probability distribution differes from a hypothesized distribution. It is used when we have two samples coming from two populations that can be different.  \n",
    "\n",
    ">If the p-value is lower than our threshold of 0.05, so we reject the null hypothesis in favor of the default “two-sided” alternative: the data were not drawn from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.6091470190356556, pvalue=2.4700771372158504e-216, statistic_location=0.0410081412417565, statistic_sign=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_2samp(oof_preds_synth[target==0], oof_preds_synth[target==1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying RecursiveFeatureElimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0900333374972037\n",
      "{'avg_glucose_level': 0.0114814154900168, 'bmi': 0.002188074390195749, 'age': 0.04421995300609483, 'heart_disease': 0.000671441535687517, 'hypertension': 0.006686764700367692}\n",
      "['hypertension', 'heart_disease', 'bmi']\n"
     ]
    }
   ],
   "source": [
    "# initialize linear regresion estimator\n",
    "X = train_synthetic_df.drop(\"stroke\", axis=1)\n",
    "y = train_synthetic_df[\"stroke\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# initialize feature selector\n",
    "tr = RecursiveFeatureElimination(estimator=linear_model, scoring=\"r2\", cv=3)\n",
    "Xt = tr.fit_transform(X_train, y_train)\n",
    "print(tr.initial_model_performance_)\n",
    "print(tr.performance_drifts_)\n",
    "print(tr.features_to_drop_)\n",
    "del X, y, X_train, X_test, y_train, y_test, linear_model, tr, Xt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is based off of information from Kaggle\n",
    "def generate_features(df):\n",
    "    df['age/bmi'] = df.age / df.bmi\n",
    "    df['age*bmi'] = df.age * df.bmi\n",
    "    df['bmi/prime'] = df.bmi / 25\n",
    "    df['obesity'] = df.avg_glucose_level * df.bmi / 1000\n",
    "    df['blood_heart']= df.hypertension*df.heart_disease\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = s_categorical + binary\n",
    "features = categorical + continous_numerical + ['age/bmi', 'age*bmi', 'bmi/prime', 'obesity', 'blood_heart']\n",
    "rfe_features =[\n",
    "    'age', 'avg_glucose_level', 'bmi', 'ever_married_Yes', 'gender_Male',\n",
    "    'hypertension_0', 'smoking_status_Unknown', 'smoking_status_formerly smoked',\n",
    "    'smoking_status_never smoked', 'work_type_Self-employed', 'work_type_children'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Submission Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_world_df = pd.read_csv('./data/real-world-data/healthcare-dataset-stroke-data.csv',)\n",
    "\n",
    "train_df = pd.read_csv('./data/synthetic-data/train.csv', index_col=0)\n",
    "test_df = pd.read_csv('./data/synthetic-data/test.csv', index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoost_model(synthetic_train_df, real_world_df, train_df, test_df_c, real_world_target, encoder):\n",
    "    # cast categorical features as categorical type\n",
    "    synthetic_train_df[categorical] = (synthetic_train_df[categorical].astype('category'))\n",
    "    real_world_df[categorical] = (real_world_df[categorical].astype('category'))\n",
    "\n",
    "\n",
    "    target = train_df['stroke']\n",
    "    # Grab Target\n",
    "    oof_preds = pd.Series(0, index=train_df.index, name='stroke')\n",
    "    test_preds = pd.Series(0, index=test_df.index, name='stroke')\n",
    "\n",
    "    train_auc, val_auc = [], []\n",
    "    pipelines = []\n",
    "\n",
    "    for fold, (train_indx, val_indx) in enumerate(cv.split(train_df, target)):\n",
    "        pipeline = []\n",
    "        X_train, y_train = synthetic_train_df.iloc[train_indx], target.iloc[train_indx]\n",
    "        X_val, y_val = synthetic_train_df.iloc[val_indx], target.iloc[val_indx]\n",
    "        X_test = test_df_c.copy()\n",
    "\n",
    "        # concat prev dataset\n",
    "        X_train = pd.concat([X_train, real_world_df], axis=0)\n",
    "        y_train = pd.concat([y_train, real_world_target])\n",
    "\n",
    "        X_train = X_train.copy()\n",
    "        X_val = X_val.copy()\n",
    "\n",
    "\n",
    "        model = XGBClassifier(\n",
    "            random_state=42, learning_rate=1e-2,\n",
    "            n_estimators=3000,\n",
    "            tree_method='gpu_hist',\n",
    "            callbacks=[\n",
    "                EarlyStopping(100, save_best=True, maximize=False),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Fit encoder\n",
    "        X_train = encoder.fit_transform(X_train)\n",
    "        X_val = encoder.transform(X_val)\n",
    "        X_test = encoder.transform(X_test)\n",
    "        pipeline.append(encoder)\n",
    "\n",
    "        # filter columns by RFE columns\n",
    "        X_train = X_train[X_train.columns.intersection(rfe_features)]\n",
    "        X_val = X_val[X_val.columns.intersection(rfe_features)]\n",
    "        X_test = X_test[X_test.columns.intersection(rfe_features)]\n",
    "\n",
    "        print('_'*50)\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val,y_val)],\n",
    "            verbose=1000,\n",
    "        )\n",
    "\n",
    "        oof_preds.iloc[val_indx] = model.predict_proba(X_val)[:, 1]\n",
    "        test_preds += model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        train_auc.append(roc_auc_score(y_train, model.predict_proba(X_train)[:, 1]))\n",
    "        val_auc.append(roc_auc_score(y_val, model.predict_proba(X_val)[:, 1]))\n",
    "\n",
    "        pipeline.append(model)\n",
    "        pipelines.append(pipeline)\n",
    "\n",
    "        print(f'Val AUC: {val_auc[-1]}')\n",
    "\n",
    "    print()\n",
    "    print(f'Mean Val AUC: {np.mean(val_auc)}')\n",
    "    print(f'OOF AUC: {roc_auc_score(target, oof_preds)}')\n",
    "    return test_preds, pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_mean(real_world_df):\n",
    "    mean_imputer = SimpleImputer(strategy=\"mean\")\n",
    "    real_world_df = real_world_df.copy()\n",
    "    real_world_df[\"bmi\"] = mean_imputer.fit_transform(real_world_df[\"bmi\"].values.reshape(-1,1))\n",
    "    print(\"Missing values after imputing with mean: \",sum(real_world_df.isnull().sum()))\n",
    "    return real_world_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_dt(real_world_df):    \n",
    "    DT_bmi_pipe = Pipeline( steps=[ \n",
    "                                (\"scale\",StandardScaler()),\n",
    "                                (\"lr\",DecisionTreeRegressor(random_state=42))\n",
    "                                ])\n",
    "    real_world_df = real_world_df.copy()\n",
    "    X = real_world_df[[\"age\",\"gender\",\"bmi\"]].copy()\n",
    "    X.gender = X.gender.replace({\"Male\":0,\"Female\":1,\"Other\":-1}).astype(np.uint8)\n",
    "\n",
    "    missing = X[X.bmi.isna()]\n",
    "    X = X[~X.bmi.isna()]\n",
    "    Y = X.pop(\"bmi\")\n",
    "    DT_bmi_pipe.fit(X,Y)\n",
    "    predicted_bmi = pd.Series(DT_bmi_pipe.predict(missing[[\"age\",\"gender\"]]),index=missing.index)\n",
    "    real_world_df.loc[missing.index,\"bmi\"] = predicted_bmi\n",
    "\n",
    "    print(\"Missing values after decision tree regressor: \",sum(real_world_df.isnull().sum()))\n",
    "    return real_world_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after decision tree regressor:  0\n",
      "Missing values after imputing with mean:  0\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Generate feature engineering\n",
    "synthetic_train_df = generate_features(train_df.copy())\n",
    "test_df_c = generate_features(test_df.copy())\n",
    "real_world_df_dt = impute_dt(real_world_df)\n",
    "real_world_df_mean = impute_mean(real_world_df)\n",
    "real_world_df_dt = generate_features(real_world_df_dt.copy())\n",
    "real_world_df_mean = generate_features(real_world_df_mean.copy())\n",
    "replace_unknows_rw = real_world_df_mean.copy()\n",
    "replace_unknown_s = synthetic_train_df.copy()\n",
    "replace_unknows_rw[\"smoking_status\"] = replace_unknows_rw[\"smoking_status\"].replace(\"Unknown\", \"never smoked\")\n",
    "replace_unknown_s[\"smoking_status\"] = replace_unknown_s[\"smoking_status\"].replace(\"Unknown\", \"never smoked\")\n",
    "\n",
    "real_world_target = real_world_df[\"stroke\"]\n",
    "\n",
    "# filter features \n",
    "synthetic_train_df = synthetic_train_df[features]\n",
    "test_df_c = test_df_c[features]\n",
    "real_world_df_dt = real_world_df_dt[features]\n",
    "real_world_df_mean = real_world_df_mean[features]\n",
    "replace_unknows_rw = replace_unknows_rw[features]\n",
    "replace_unknown_s = replace_unknown_s[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68453\n",
      "[929]\tvalidation_0-logloss:0.12710\n",
      "Val AUC: 0.8864452229574844\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68455\n",
      "[645]\tvalidation_0-logloss:0.12764\n",
      "Val AUC: 0.8772976947363869\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68448\n",
      "[584]\tvalidation_0-logloss:0.12510\n",
      "Val AUC: 0.8803521216768916\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68457\n",
      "[775]\tvalidation_0-logloss:0.12507\n",
      "Val AUC: 0.8954925017041582\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68453\n",
      "[756]\tvalidation_0-logloss:0.12277\n",
      "Val AUC: 0.8922322848703216\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68454\n",
      "[650]\tvalidation_0-logloss:0.12744\n",
      "Val AUC: 0.8863569967864446\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68453\n",
      "[703]\tvalidation_0-logloss:0.12507\n",
      "Val AUC: 0.8835546033910042\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68451\n",
      "[775]\tvalidation_0-logloss:0.13057\n",
      "Val AUC: 0.8740654180326981\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68457\n",
      "[696]\tvalidation_0-logloss:0.12831\n",
      "Val AUC: 0.8828350699516343\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68456\n",
      "[773]\tvalidation_0-logloss:0.12521\n",
      "Val AUC: 0.8843336471148332\n",
      "\n",
      "Mean Val AUC: 0.8842965561221856\n",
      "OOF AUC: 0.8840207775423436\n"
     ]
    }
   ],
   "source": [
    "preds_ss_mean, pipelines = XGBoost_model(synthetic_train_df, real_world_df_mean, train_df, test_df_c, real_world_target, encoder=StringSimilarityEncoder(variables=categorical))\n",
    "preds_ss_mean /= len(pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68453\n",
      "[816]\tvalidation_0-logloss:0.12563\n",
      "Val AUC: 0.8865317244063837\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68455\n",
      "[819]\tvalidation_0-logloss:0.12773\n",
      "Val AUC: 0.877459884953073\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68448\n",
      "[579]\tvalidation_0-logloss:0.12528\n",
      "Val AUC: 0.878328433878664\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68457\n",
      "[768]\tvalidation_0-logloss:0.12570\n",
      "Val AUC: 0.8947043285616906\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68453\n",
      "[850]\tvalidation_0-logloss:0.12453\n",
      "Val AUC: 0.8900033542160333\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68455\n",
      "[640]\tvalidation_0-logloss:0.12758\n",
      "Val AUC: 0.8856536934246546\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68453\n",
      "[712]\tvalidation_0-logloss:0.12467\n",
      "Val AUC: 0.8841172460804363\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68451\n",
      "[799]\tvalidation_0-logloss:0.12941\n",
      "Val AUC: 0.8760238473939905\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68456\n",
      "[835]\tvalidation_0-logloss:0.12761\n",
      "Val AUC: 0.8862379762175263\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68456\n",
      "[731]\tvalidation_0-logloss:0.12520\n",
      "Val AUC: 0.885621233269495\n",
      "\n",
      "Mean Val AUC: 0.8844681722401948\n",
      "OOF AUC: 0.8844922150000689\n"
     ]
    }
   ],
   "source": [
    "preds_ss_dt, pipelines = XGBoost_model(synthetic_train_df, real_world_df_dt, train_df, test_df_c, real_world_target, encoder=StringSimilarityEncoder(variables=categorical))\n",
    "preds_ss_dt /= len(pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ss_dt.rename('stroke', inplace=True)\n",
    "preds_ss_dt.to_csv('./submissions/submission_ss_dt.csv') # Public Score: 0.8658\n",
    "preds_ss_mean.rename('stroke', inplace=True)\n",
    "preds_ss_mean.to_csv('submissions/submission_ss_mean.csv')  # Public Score: 0.8672"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that imputing with mean fits better to our model.    \n",
    "Lets try impting with mean and using OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68455\n",
      "[805]\tvalidation_0-logloss:0.12690\n",
      "Val AUC: 0.8832230439859867\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68454\n",
      "[876]\tvalidation_0-logloss:0.12842\n",
      "Val AUC: 0.8747783400371956\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68449\n",
      "[576]\tvalidation_0-logloss:0.12493\n",
      "Val AUC: 0.8806396983640081\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68457\n",
      "[709]\tvalidation_0-logloss:0.12429\n",
      "Val AUC: 0.8992309986366734\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68454\n",
      "[756]\tvalidation_0-logloss:0.12264\n",
      "Val AUC: 0.8949589379037233\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68455\n",
      "[644]\tvalidation_0-logloss:0.12700\n",
      "Val AUC: 0.8885967474924531\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68453\n",
      "[705]\tvalidation_0-logloss:0.12474\n",
      "Val AUC: 0.8843877473734325\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68451\n",
      "[1000]\tvalidation_0-logloss:0.12913\n",
      "[1313]\tvalidation_0-logloss:0.12848\n",
      "Val AUC: 0.8809902511334005\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68455\n",
      "[761]\tvalidation_0-logloss:0.12622\n",
      "Val AUC: 0.8874444119842894\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68456\n",
      "[734]\tvalidation_0-logloss:0.12584\n",
      "Val AUC: 0.8852317114075805\n",
      "\n",
      "Mean Val AUC: 0.8859481888318743\n",
      "OOF AUC: 0.8856868503513107\n"
     ]
    }
   ],
   "source": [
    "preds_oh, pipelines = XGBoost_model(synthetic_train_df, real_world_df_mean, train_df, test_df_c, real_world_target, encoder=OneHotEncoder(variables=categorical))\n",
    "preds_oh /= len(pipelines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in our LogisticRegressor, StringSimilarityEncoder fits *very slightly* better than OneHotEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_oh.rename('stroke', inplace=True)\n",
    "preds_oh.to_csv('./submissions/submission_oh.csv')  # Public Score: 0.86705"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try replacing the \"Unknown\"s in `smoking_status` by \"never smoked\" as we discussed in the EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68453\n",
      "[779]\tvalidation_0-logloss:0.12595\n",
      "Val AUC: 0.8880076553782276\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68453\n",
      "[811]\tvalidation_0-logloss:0.12862\n",
      "Val AUC: 0.8748215907616452\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68448\n",
      "[575]\tvalidation_0-logloss:0.12568\n",
      "Val AUC: 0.8798781526925699\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68455\n",
      "[806]\tvalidation_0-logloss:0.12413\n",
      "Val AUC: 0.8967120398773005\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68454\n",
      "[754]\tvalidation_0-logloss:0.12405\n",
      "Val AUC: 0.8898194133367957\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68456\n",
      "[761]\tvalidation_0-logloss:0.12671\n",
      "Val AUC: 0.8867627487259389\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68451\n",
      "[743]\tvalidation_0-logloss:0.12331\n",
      "Val AUC: 0.887114400406834\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68451\n",
      "[1000]\tvalidation_0-logloss:0.12816\n",
      "[1060]\tvalidation_0-logloss:0.12816\n",
      "Val AUC: 0.8799298860648553\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68456\n",
      "[776]\tvalidation_0-logloss:0.12518\n",
      "Val AUC: 0.8928760779476526\n",
      "__________________________________________________\n",
      "[0]\tvalidation_0-logloss:0.68457\n",
      "[733]\tvalidation_0-logloss:0.12496\n",
      "Val AUC: 0.8862974865019855\n",
      "\n",
      "Mean Val AUC: 0.8862219451693806\n",
      "OOF AUC: 0.8861399544296895\n"
     ]
    }
   ],
   "source": [
    "preds_unkw, pipelines = XGBoost_model(replace_unknown_s, replace_unknows_rw, train_df, test_df_c, real_world_target, encoder=StringSimilarityEncoder(variables=categorical))\n",
    "preds_unkw /= len(pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_unkw.rename('stroke', inplace=True)\n",
    "preds_unkw.to_csv('./submissions/submission_unkwn.csv')  # Public Score: 0.86445"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expected that replacing the \"Unknown\"s in `smoking_status` by \"never smoked\" since they are close to the attributes of \"never smoked\" would reduce the noise and result in a better model, however this is not the case. Our final submisson is StringSimilarityEncoder with imputed mean."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
